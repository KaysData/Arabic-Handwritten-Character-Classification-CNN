{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ec2-user/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data-set is composed of 16,800 characters written by 60 participants, the age range is between 19 to 40 years, and 90% of participants are right-hand. Each participant wrote each character (from ’alef’ to ’yeh’) ten times on two forms as shown in Fig. 7(a) & 7(b). The forms were scanned at the resolution of 300 dpi. Each block is segmented automatically using Matlab 2016a to determining the coordinates for each block. The database is partitioned into two sets: a training set (13,440 characters to 480 images per class) and a test set (3,360 characters to 120 images per class). Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from a single institution (to ensure variability of the test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setting up the Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabicTrainImages = pd.read_csv(\"csvTrainImages 13440x1024.csv\")\n",
    "arabicTrainLabels = pd.read_csv(\"csvTrainLabel 13440x1.csv\")\n",
    "arabicTestImages = pd.read_csv(\"csvTestImages 3360x1024.csv\")\n",
    "arabicTestLabel = pd.read_csv(\"csvTestLabel 3360x1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13439, 1024)\n",
      "(13439, 1)\n",
      "(3359, 1024)\n",
      "(3359, 1)\n"
     ]
    }
   ],
   "source": [
    "print(arabicTrainImages.shape)\n",
    "print(arabicTrainLabels.shape)\n",
    "print(arabicTestImages.shape)\n",
    "print(arabicTestLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImgs = arabicTrainImages.values\n",
    "trainLabels = arabicTrainLabels.values \n",
    "testImgs = arabicTestImages.values\n",
    "testLabels = arabicTestLabel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X,y):\n",
    "\n",
    "    data = np.hstack((X,y))\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:,:-1]\n",
    "    y = data[:, -1]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "[trainImgs, trainLabels] = shuffle_data(trainImgs,trainLabels)\n",
    "[testImgs, testLabels] = shuffle_data(testImgs,testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainImgs.reshape(13439, 32, 32,1).astype('uint8')\n",
    "y_train = trainLabels.astype('uint8')\n",
    "X_test = testImgs.reshape(3359, 32, 32,1).astype('uint8')\n",
    "y_test = testLabels.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.transpose(X_train,(0,2,1,3))\n",
    "X_test = np.transpose(X_test,(0,2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalization(X):\n",
    "    out = X/255\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = image_normalization(X_train)\n",
    "X_test = image_normalization(X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "#plt.imshow(X_test[index], cmap='Blues')\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "#plt.imshow(X_test[index], cmap='Blues')\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "#plt.imshow(X_test[index], cmap='Blues')\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=28):\n",
    "    # one-hot encodes the 28 possible labels\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n,vals))\n",
    "    out[range(n), vec-1] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "y_test_one_hot = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train_one_hot[0:2])\n",
    "#print()\n",
    "#print(y_test_one_hot[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(X,y, num_of_batches = 10):\n",
    "    #splits data into batches, assumes the data has already been shuffled\n",
    "    #assumes data is organized where each row in the 0th axis is it's own sample \n",
    "\n",
    "    n = len(X)\n",
    "    batch_size = math.floor(float(n)/float(num_of_batches))\n",
    "\n",
    "    all_X_batches = []\n",
    "    all_y_batches = []\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "    for i in range(num_of_batches):\n",
    "        XBatch = X[batch_start: batch_end]\n",
    "        all_X_batches.append(XBatch)\n",
    "\n",
    "        yBatch = y[batch_start: batch_end]\n",
    "        all_y_batches.append(yBatch)\n",
    "        batch_start = batch_end\n",
    "        batch_end += batch_size\n",
    "\n",
    "\n",
    "    return all_X_batches, all_y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchFeed:\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.all_X_batches = []\n",
    "        self.all_y_batches = []\n",
    "        self.test_batch = [X_test, y_test]\n",
    "        \n",
    "        self.train_images = X_train\n",
    "        self.train_labels = y_train\n",
    "        \n",
    "        self.num_of_batches = 0\n",
    "\n",
    "        \n",
    "    def set_up_batches(self, num_of_batches= 10):\n",
    "        \n",
    "        self.num_of_batches = num_of_batches\n",
    "        \n",
    "        self.all_X_batches, self.all_y_batches = make_batches(\n",
    "            self.train_images, self.train_labels, \n",
    "            num_of_batches = num_of_batches)\n",
    "        \n",
    "    def next_batch(self):\n",
    "        X = self.all_X_batches[self.i]\n",
    "        y = self.all_y_batches[self.i]\n",
    "        self.i += 1\n",
    "        if (self.num_of_batches == self.i):\n",
    "            self.i = 0\n",
    "            \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = BatchFeed(X_train, y_train_one_hot, X_test, y_test_one_hot)\n",
    "bf.set_up_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,32,32,1])## dimensions fix\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides =[1,1,1,1], padding ='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], \n",
    "                      strides=[1,2,2,1], padding = 'SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W + b))\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "        input_size = int(input_layer.get_shape()[1])\n",
    "        W = init_weights([input_size, size])\n",
    "        b = init_bias([size])\n",
    "        return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x, shape = [4,4,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling, shape= [4,4,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*8*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1,8*8*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob = hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-a6582372d089>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits = y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.06370944\n",
      "\n",
      "\n",
      "Currently on step 5000\n",
      "Accuracy is:\n",
      "0.8901459\n",
      "\n",
      "\n",
      "Currently on last step\n",
      "Accuracy is:\n",
      "0.9336112\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NUM_THREADS = 1\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=NUM_THREADS))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10000):\n",
    "        batch = bf.next_batch()\n",
    "        sess.run(train, feed_dict = {x:batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        \n",
    "        # print out stats every 100 steps \n",
    "        if i%5000 == 0:\n",
    "\n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # test the train model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print(sess.run(acc, feed_dict = {\n",
    "                x:bf.test_batch[0], y_true: bf.test_batch[1], hold_prob:1.0}))\n",
    "            print('\\n')\n",
    "            \n",
    "    print('Currently on last step')\n",
    "    print('Accuracy is:')\n",
    "    # test the train model\n",
    "    matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "    print(sess.run(acc, feed_dict = {\n",
    "        x:bf.test_batch[0], y_true: bf.test_batch[1], hold_prob:1.0}))\n",
    "    print('\\n')\n",
    "        \n",
    "    saver.save(sess,'./Arabic CNN.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589.203708463\n"
     ]
    }
   ],
   "source": [
    "stop = timeit.default_timer()\n",
    "\n",
    "print( stop - start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
